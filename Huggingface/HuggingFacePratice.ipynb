{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMIds3yEKztnAOITU27hjTj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-Tqgtxo9wnm","executionInfo":{"status":"ok","timestamp":1681717682138,"user_tz":-540,"elapsed":10729,"user":{"displayName":"솔봉 SOLBON","userId":"01860439525443421279"}},"outputId":"820721ce-e077-4fe1-ba27-a527936b4548"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# transformer 패키지 설치\n","# !pip install transformers\n","\n","# 필요한 패키지 가져오기\n","from transformers import AutoModel, AutoTokenizer, BertTokenizer\n","# 사용할 모델 이름\n","MODEL_NAME = \"bert-base-multilingual-cased\" # 원하는 모델 이름은 사이트에서 검색\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","source":["text = \"아라시는 쟈니스 소속 아이돌이다.\"\n","\n","tokenized_input_text = tokenizer(text, return_tensors=\"pt\")\n","# return_tensors=\"pt\" -> pytorch tensor 형태로 변환\n","for key, value in tokenized_input_text.items ():\n","\tprint(\"{}: \\n\\t{}\".format(key, value))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZCosQB6-xsb","executionInfo":{"status":"ok","timestamp":1681714732294,"user_tz":-540,"elapsed":9,"user":{"displayName":"솔봉 SOLBON","userId":"01860439525443421279"}},"outputId":"f0ae74d4-5597-4751-c898-a0a8a8060158"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input_ids: \n","\ttensor([[   101,   9519,  17342,  14040,  11018,   9662,  25503,  12605,  96770,\n","           9519,  10739, 118794,  11925,    119,    102]])\n","token_type_ids: \n","\ttensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","attention_mask: \n","\ttensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"]}]},{"cell_type":"code","source":["# Single segment input\n","single_seg_input = tokenizer(\"아라시는 쟈니스 소속 아이돌이다.\")\n","\n","# Multiple segment input\n","multi_seg_input = tokenizer(\"아라시는 쟈니스 소속 아이돌이다.\", \"그들은 활동중단 상태에 있다.\")\n","\n","print(\"Single segment token (str) : {}\".format(tokenizer.convert_ids_to_tokens(single_seg_input['input_ids'])))\n","print(\"Single segment token (int) : {}\".format(single_seg_input['input_ids']))\n","print(\"Single segment type : {}\".format(single_seg_input['token_type_ids']))\n","\n","# Segments are concatened in the input to the model, with\n","print()\n","print(\"Multi segment token (str) : {}\".format(tokenizer.convert_ids_to_tokens(multi_seg_input['input_ids'])))\n","print(\"Multi segment token (int) : {}\".format(multi_seg_input['input_ids']))\n","print(\"Multi segment type : {}\".format(multi_seg_input['token_type_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltlAX1gg-1dr","executionInfo":{"status":"ok","timestamp":1681714866006,"user_tz":-540,"elapsed":7,"user":{"displayName":"솔봉 SOLBON","userId":"01860439525443421279"}},"outputId":"36f08508-9995-482a-b097-d3920946d497"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Single segment token (str) : ['[CLS]', '아', '##라', '##시', '##는', '쟈', '##니', '##스', '소속', '아', '##이', '##돌', '##이다', '.', '[SEP]']\n","Single segment token (int) : [101, 9519, 17342, 14040, 11018, 9662, 25503, 12605, 96770, 9519, 10739, 118794, 11925, 119, 102]\n","Single segment type : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","\n","Multi segment token (str) : ['[CLS]', '아', '##라', '##시', '##는', '쟈', '##니', '##스', '소속', '아', '##이', '##돌', '##이다', '.', '[SEP]', '그들은', '활', '##동', '##중', '##단', '상', '##태', '##에', '있다', '.', '[SEP]']\n","Multi segment token (int) : [101, 9519, 17342, 14040, 11018, 9662, 25503, 12605, 96770, 9519, 10739, 118794, 11925, 119, 102, 103087, 9996, 18778, 41693, 24989, 9414, 83616, 10530, 11506, 119, 102]\n","Multi segment type : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}]},{"cell_type":"code","source":["# Dictionary 값을 불러오면 끝!\n","print(tokenized_input_text['input_ids']) # input text를 tokenizing한 후 vocab의 id\n","print(tokenized_input_text.input_ids)\n","print(tokenized_input_text['token_type_ids']) # segment id (sentA or sentB)\n","print(tokenized_input_text['attention_mask']) # special token (pad, cls, sep) or not\n","print(tokenized_input_text.attention_mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUHr-CyICnne","executionInfo":{"status":"ok","timestamp":1681715299906,"user_tz":-540,"elapsed":632,"user":{"displayName":"솔봉 SOLBON","userId":"01860439525443421279"}},"outputId":"0a41bf58-dfb4-4a8b-f63c-a85f8d62c6b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[   101,   9519,  17342,  14040,  11018,   9662,  25503,  12605,  96770,\n","           9519,  10739, 118794,  11925,    119,    102]])\n","tensor([[   101,   9519,  17342,  14040,  11018,   9662,  25503,  12605,  96770,\n","           9519,  10739, 118794,  11925,    119,    102]])\n","tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"]}]},{"cell_type":"code","source":["tokenized_text = tokenizer.tokenize(text)\n","print(tokenized_text)\n","input_ids = tokenizer.encode(text)\n","print(input_ids)\n","decoded_ids = tokenizer.decode(input_ids)\n","print(decoded_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v9bKdrjnEQ7V","executionInfo":{"status":"ok","timestamp":1681715719302,"user_tz":-540,"elapsed":685,"user":{"displayName":"솔봉 SOLBON","userId":"01860439525443421279"}},"outputId":"7d96c824-94ce-49ee-93b1-d47fc989956d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['아', '##라', '##시', '##는', '쟈', '##니', '##스', '소속', '아', '##이', '##돌', '##이다', '.']\n","[101, 9519, 17342, 14040, 11018, 9662, 25503, 12605, 96770, 9519, 10739, 118794, 11925, 119, 102]\n","[CLS] 아라시는 쟈니스 소속 아이돌이다. [SEP]\n"]}]},{"cell_type":"code","source":["tokenized_text = tokenizer.tokenize(text, add_special_tokens = False)\n","print(tokenized_text)\n","input_ids = tokenizer.encode(text, add_special_tokens= False)\n","print(input_ids)\n","decoded_ids = tokenizer.decode(input_ids)\n","print(decoded_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqZZJMUqEREm","executionInfo":{"status":"ok","timestamp":1681715835765,"user_tz":-540,"elapsed":517,"user":{"displayName":"솔봉 SOLBON","userId":"01860439525443421279"}},"outputId":"e0f12127-3981-403c-f9a6-4fdb2d7df926"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['아', '##라', '##시', '##는', '쟈', '##니', '##스', '소속', '아', '##이', '##돌', '##이다', '.']\n","[9519, 17342, 14040, 11018, 9662, 25503, 12605, 96770, 9519, 10739, 118794, 11925, 119]\n","아라시는 쟈니스 소속 아이돌이다.\n"]}]},{"cell_type":"code","source":["tokenized_text = tokenizer.tokenize(\n","text,\n","add_special_tokens= False,\n","max_length = 5,\n","truncation=True # 5개의 token만 살리고 뒤는 자르기\n",")\n","print(tokenized_text)\n","\n","input_ids = tokenizer.encode(\n","text,\n","add_special_tokens=False,\n","max_length=5,\n","truncation=True\n",")\n","print(input_ids)\n","decoded_ids = tokenizer.decode(input_ids)\n","print(decoded_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dc5Rom5mGDz2","executionInfo":{"status":"ok","timestamp":1681716169055,"user_tz":-540,"elapsed":498,"user":{"displayName":"솔봉 SOLBON","userId":"01860439525443421279"}},"outputId":"a2895d95-024d-47f7-9900-dcc807341975"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['아', '##라', '##시', '##는', '쟈']\n","[9519, 17342, 14040, 11018, 9662]\n","아라시는 쟈\n"]}]},{"cell_type":"code","source":["print(tokenizer.pad_token)\n","print(tokenizer.pad_token_id)\n","\n","tokenized_text = tokenizer.tokenize(\n","\ttext,\n","\tadd_special_tokens=False,\n","\tmax_length=20,\n","\tpadding=\"max_length\"\n","\t)\n","print(tokenized_text)\n","\n","input_ids = tokenizer.encode(\n","\ttext,\n","\tadd_special_tokens = False,\n","\tmax_length =20,\n","\tpadding = \"max_length\"\n","\t)\n","print(input_ids)\n","\n","decoded_ids = tokenizer.decode(input_ids)\n","print(decoded_ids)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1CmMX0hGDtZ","executionInfo":{"status":"ok","timestamp":1681716409409,"user_tz":-540,"elapsed":464,"user":{"displayName":"솔봉 SOLBON","userId":"01860439525443421279"}},"outputId":"3a46b833-82dc-4431-dd57-b03fd576d247"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[PAD]\n","0\n","['아', '##라', '##시', '##는', '쟈', '##니', '##스', '소속', '아', '##이', '##돌', '##이다', '.', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","[9519, 17342, 14040, 11018, 9662, 25503, 12605, 96770, 9519, 10739, 118794, 11925, 119, 0, 0, 0, 0, 0, 0, 0]\n","아라시는 쟈니스 소속 아이돌이다. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["text = \"안녕하세요. 저는 지금 카페에 있습니다.\"\n","\n","tokenized_text = tokenizer.tokenize(text, add_special_tokens =False)\n","print(tokenized_text)\n","input_ids = tokenizer.encode(text, add_special_tokens=False)\n","print(input_ids)\n","decoded_ids = tokenizer.decode(input_ids)\n","print(decoded_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJGwbD-XLvKc","executionInfo":{"status":"ok","timestamp":1681717694728,"user_tz":-540,"elapsed":445,"user":{"displayName":"솔봉 SOLBON","userId":"01860439525443421279"}},"outputId":"82033a3b-b377-4503-a7bc-f2c9ab11ce0b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["['안', '##녕', '##하', '##세', '##요', '.', '저', '##는', '지', '##금', '카', '##페', '##에', '있', '##습', '##니다', '.']\n","[9521, 118741, 35506, 24982, 48549, 119, 9663, 11018, 9706, 40032, 9786, 119391, 10530, 9647, 119081, 48345, 119]\n","안녕하세요. 저는 지금 카페에 있습니다.\n"]}]},{"cell_type":"code","source":["added_token_num = tokenizer.add_tokens([\"안녕\", \"저\", \"지금\", \"카페\", \"있습\"])\n","print(added_token_num)\n","\n","tokenized_text = tokenizer.tokenize(text, add_special_tokens=False)\n","print(tokenized_text)\n","input_ids = tokenizer.encode(text, add_special_tokens=False)\n","print(input_ids)\n","decoded_ids = tokenizer.decode(input_ids)\n","print(decoded_ids)"],"metadata":{"id":"9OHG9zg_McO5","executionInfo":{"status":"ok","timestamp":1681717841684,"user_tz":-540,"elapsed":519,"user":{"displayName":"솔봉 SOLBON","userId":"01860439525443421279"}},"outputId":"7f517c85-298a-4898-bfa0-333b4f31da34","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","['안녕', '하', '##세', '##요', '.', '저', '##는', '지금', '카페', '에', '있습', '니', '##다', '.']\n","[119547, 9952, 24982, 48549, 119, 9663, 11018, 119548, 119549, 9559, 119550, 9049, 11903, 119]\n","안녕 하세요. 저는 지금 카페 에 있습 니다.\n"]}]}]}