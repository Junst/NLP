{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 개체명 인식 (Named Entity Recognition)"
      ],
      "metadata": {
        "id": "3w4C2RrvAxmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "개체명 인식이란 문장 내에 포함된 어떤 단어가 인물, 장소, 날짜 등을 의미하는 단어인지 인식하는 것이다. 딥러닝 모델이나 확률 모델 등을 이용해 문장에서 개체명을 인식하는 프로그램을 개체명 인식기라 부른다. 예를 들어 날짜와 지역에 대해 개체 인식을 할 수 있는 개체명 인식 모델이 있다고 했을 때, 다음과 같이 문장을 분류한다.\n",
        "\n",
        "-  1. 입력 문장 : 내일 파리 날씨 알려줘\n",
        "-  2. 문장 의도 분류 : 날씨 요청\n",
        "-  3. 개체명 인식 결과 : <br>\n",
        "  내일 - 날짜 <br>\n",
        "  파리 - 지역\n",
        "\n",
        "개체명 인식 모델을 만들기 위해서는 우선 BIO 표기법을 알아야 한다. BIO란, Beginning, Inside, Outside의 약자로 각 토큰마다 태그를 붙이기 위해 사용한다. B (beginning)는 개체명이 시작되는 단어에 'B-개체명'으로 태그 되며, I(inside)는 'B-개체명'과 연결되는 단어일 때 'I-개체명'으로 태그된다. 마지막으로 O(outside)는 개체명 이외의 모든 토큰에 태그된다. \n",
        "\n",
        "오늘부터 사쿠라이 쇼는 게이오 대학교에 등교합니다.\n",
        "\n",
        "오늘 / B-Date, 사쿠라이 / B-Person, 쇼 / I-Person, 게이오 / B-University, 대학교 / I-University, 근무 / o, 부터 / o, 는 / o, 에 / o, 합니다. / o   "
      ],
      "metadata": {
        "id": "PIssvSwNA1ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기 예제에서 사용하는 BIO 태그 학습 데이터셋은 HLCT 2016에서 제공하는 말뭉치 데이터를 수정한 KoreanNERCorpus입니다.<br>\n",
        "[github.com/machingreading/KoreanNERTCorpus](https://github.com/machingreading/KoreanNERTCorpus)"
      ],
      "metadata": {
        "id": "khsLzhOgD4D5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train.txt 파일 내용을 살펴보면, ;으로 시작하는 문장 라인은 원본 문장에 해당하며, $로 시작하는 문장 라인은 해당 문장에서 NER 처리된 결과를 의미한다.\n",
        "그다음 라인부터는  토큰 번호, 단어 토큰, 품사 태그, BIO 태그로 구성된 열이 존재한다. 여기서는 단어 토큰과 BIO 태그 정보만 학습 데이터셋으로 사용한다.\n",
        "\n",
        "구현하는 개체명 인식기의 원리는 다음과 같다. 해당 모델은 단어 토큰을 입력했을 때 출력되는 NER 태그값을 예측하는 문제다. 예를 들어 '삼성전자'를 입력했을 때 단체를 뜻하는 B_OG(oraganization) 태그가 출력되도록 모델을 학습한다."
      ],
      "metadata": {
        "id": "z7P4SLzvOD5i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ezP0nP9AAwuC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 데이터 구조에 맞게 파일을 읽어와 문장 라인별로 토큰 번호, 단어 토크, 품사 태그, BIO 태그 정보를 불러온다."
      ],
      "metadata": {
        "id": "Aui1i_vyTAYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 파일 불러오기\n",
        "def read_file(file_name):\n",
        "  sents = []\n",
        "  with open(file_name, 'r', encoding= 'utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "    for idx, l in enumerate(lines):\n",
        "      if l[0]== ';' and lines[idx+1][0] == '$':\n",
        "        this_sent = []\n",
        "      elif l[0] == '$' and lines[idx -1][0] == ';':\n",
        "        continue\n",
        "      elif l[0] == '\\n':\n",
        "        sents.append(this_sent)\n",
        "      else :\n",
        "        this_sent.append(tuple(l.split()))\n",
        "  return sents"
      ],
      "metadata": {
        "id": "kf7plPXKFZ5t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용 말뭉치 데이터를 불러옴\n",
        "corpus = read_file('train.txt')"
      ],
      "metadata": {
        "id": "9wDFVI4rFtRb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 말뭉치 데이터에서 단어와 BIO 태그만 불러와 학습용 데이터셋 생성\n",
        "sentences, tags = [], []\n",
        "for t in corpus: \n",
        "  tagged_sentence = []\n",
        "  sentence, bio_tag = [],[]\n",
        "  for w in t :\n",
        "    tagged_sentence.append((w[1],w[3]))\n",
        "    sentence.append(w[1])\n",
        "    bio_tag.append(w[3])\n",
        "\n",
        "  sentences.append(sentence)\n",
        "  tags.append(bio_tag)"
      ],
      "metadata": {
        "id": "9cNasvISGiff"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0번째 원본 문장에서 분리된 단어 토큰들이 sentences 리스트에 저장된다. 저장된 단어 시퀀스는 다음과 같은데, 이 단어 시퀀스에 해당하는 BIO 태그 정보들이 tags 리스트에 저장된다. 이때 sentences 리스트와 tags 리스트의 크기는 동일하다. 단어 시퀀스의 평균 길이값을 기준으로 시퀀스 패딩의 크기를 결정한다."
      ],
      "metadata": {
        "id": "Ez2dHEglTXNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"샘플 크기 : \\n\", len(sentences))\n",
        "print(\"0번째 샘플 문장 시퀀스 : \\n\", sentences[0])\n",
        "print(\"0번째 샘플 bio 태그 : \\n\", tags[0])\n",
        "print(\"샘플 문장 시퀀스 최대 길이 :\", max(len(l) for l in sentences))\n",
        "print(\"샘플 문장 시퀀스 평균 길이 :\", (sum(map(len, sentences))/len(sentences)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy9oFoJeGpQ-",
        "outputId": "37433d02-de9c-49ef-b458-ed2baa4c791f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플 크기 : \n",
            " 3555\n",
            "0번째 샘플 문장 시퀀스 : \n",
            " ['한편', ',', 'AFC', '챔피언스', '리그', 'E', '조', '에', '속하', 'ㄴ', '포항', '역시', '대회', '8강', '진출', '이', '불투명', '하', '다', '.']\n",
            "0번째 샘플 bio 태그 : \n",
            " ['O', 'O', 'O', 'O', 'O', 'B_OG', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "샘플 문장 시퀀스 최대 길이 : 168\n",
            "샘플 문장 시퀀스 평균 길이 : 34.03909985935302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어 시퀀스와 태그 시퀀스를 사전으로 만들기 위해 토크나이저를 정의한 후 fit_on_texts() 함수를 호출한다. 여기서 OOV는 out of vocabulary의 약자로 단어 사전에 포함되지 않은 단어를 의미한다. 단어 사전의 첫번째 인덱스 토큰값으로 'OOV'를 설정한다."
      ],
      "metadata": {
        "id": "eBDFczQzT-0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 정의\n",
        "sent_tokenizer = preprocessing.text.Tokenizer(oov_token= 'OOV') # 첫 번째 인덱스에는 OOV 사용\n",
        "sent_tokenizer.fit_on_texts(sentences)\n",
        "tag_tokenizer = preprocessing.text.Tokenizer(lower=False) # 태그 정보는 lower= False 소문자로 변환하지 않는다.\n",
        "tag_tokenizer.fit_on_texts(tags)"
      ],
      "metadata": {
        "id": "Nb0fYKVfHrbx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성된 사전 리스트를 이용해 단어와 태그 사전의 크기를 정의한다."
      ],
      "metadata": {
        "id": "fbRHktU1UQ0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 사전 및 태그 사전 크기\n",
        "vocab_size = len(sent_tokenizer.word_index)+1\n",
        "tag_size = len(tag_tokenizer.word_index)+1\n",
        "print(\"BIO 태그 사전 크기 :\", tag_size)\n",
        "print(\"단어 사전 크기 : \", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5roUo72GPOs6",
        "outputId": "3c8256ed-2d4f-4cd5-97b0-7920790da84d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIO 태그 사전 크기 : 8\n",
            "단어 사전 크기 :  13834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 만들어진 사전 데이터를 시퀀스 번호 형태로 인코딩한다."
      ],
      "metadata": {
        "id": "BcoEfpKUUTt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용 단어 시퀀스 생성\n",
        "x_train = sent_tokenizer.texts_to_sequences(sentences)\n",
        "y_train = tag_tokenizer.texts_to_sequences(tags)\n",
        "print(x_train[0])\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrU2FEWwIlLg",
        "outputId": "7bc6484c-4bee-4d87-cba8-93ad5876e2b5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[183, 11, 4276, 884, 162, 931, 402, 10, 2608, 7, 1516, 608, 145, 1361, 414, 4, 6347, 2, 8, 3]\n",
            "[1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index to word / index to NER 정의\n",
        "index_to_word = sent_tokenizer.index_word # 시퀀스 인덱스를 단어로 변환하기 위해 사용\n",
        "index_to_ner = tag_tokenizer.index_word # 시퀀스 인덱스를 NER로 변환하기 위해 사용\n",
        "index_to_ner[0]= 'PAD'"
      ],
      "metadata": {
        "id": "9lBEPd4cI6-E"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "개체명 인식 모델의 입출력 벡터 크기를 동일하게 맞추기 위해 시퀀스 패딩 작업을 한다. 벡터 크기를 위에서 계산한 단어 시퀀스의 평균 길이보다 넉넉하게 40으로 정의한다."
      ],
      "metadata": {
        "id": "lDzl7VabUY6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 패딩 처리\n",
        "max_len= 40\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, padding= 'post', maxlen= max_len)\n",
        "y_train = preprocessing.sequence.pad_sequences(y_train, padding= 'post', maxlen=max_len)"
      ],
      "metadata": {
        "id": "gkUElfyVJJBI"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`sklearn.model_selection` 모듈의 `train_test_split()` 함수를 이용해 학습용과 테스트용 데이터셋을 8:2 비율로 분리한다. "
      ],
      "metadata": {
        "id": "AU0yZKEBUhGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터와 테스트 데이터를 8:2 비율로 분리\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=.2, random_state=0)"
      ],
      "metadata": {
        "id": "tvzmkhGGJheM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이후 학습과 테스트용 출력 데이터(y_train, y_test)를 태그 사전 크기에 맞게 원-핫 인코딩한다."
      ],
      "metadata": {
        "id": "dqttrI5wUtd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력 데이터를 원-핫 인코딩\n",
        "y_train = tf.keras.utils.to_categorical(y_train,num_classes = tag_size)\n",
        "y_test = tf.keras.utils.to_categorical(y_test,num_classes = tag_size)"
      ],
      "metadata": {
        "id": "5c-G39L9JrLN"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"학습 샘플 시퀀스 형상 : \", x_train.shape)\n",
        "print(\"학습 샘플 레이블 형상 : \", x_test.shape)\n",
        "print(\"테스트 샘플 시퀀스 형상 : \", y_train.shape)\n",
        "print(\"테스트 샘플 레이블 형상 : \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqZcnba4J_el",
        "outputId": "1b7bde30-facd-4279-f963-c760662a01f9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 샘플 시퀀스 형상 :  (2844, 40)\n",
            "학습 샘플 레이블 형상 :  (711, 40)\n",
            "테스트 샘플 시퀀스 형상 :  (2844, 40, 8)\n",
            "테스트 샘플 레이블 형상 :  (711, 40, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의 (Bi-LSTM)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout,Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "SkY6TMFtKLWQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "개체 인식 모델을 순차 모델 방식으로 구현한다. tag_size만큼의 출력 뉴런에서 제일 확률 높은 출력값 1개를 선택하는 문제이기 때문에 모델 출력 계층의 활성화 함수로 softmax를 사용하며 손실 함수로 categorical_crossentropy를 사용한다."
      ],
      "metadata": {
        "id": "rfZRND1LU0p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim = 30, input_length=max_len, mask_zero= True))\n",
        "model.add(Bidirectional(LSTM(200, return_sequences=True, dropout=0.5, recurrent_dropout = 0.25)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.01), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size= 128, epochs =10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk1KUxzTKgJ0",
        "outputId": "23254d66-dcd1-4b2a-9d73-c90d8b4159ea"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - 27s 851ms/step - loss: 0.5029 - accuracy: 0.8416\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 20s 877ms/step - loss: 0.2357 - accuracy: 0.8961\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 21s 890ms/step - loss: 0.1510 - accuracy: 0.9278\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 21s 890ms/step - loss: 0.1109 - accuracy: 0.9468\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 20s 877ms/step - loss: 0.0857 - accuracy: 0.9616\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 20s 874ms/step - loss: 0.0618 - accuracy: 0.9733\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 20s 883ms/step - loss: 0.0475 - accuracy: 0.9796\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 20s 861ms/step - loss: 0.0387 - accuracy: 0.9830\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 21s 906ms/step - loss: 0.0314 - accuracy: 0.9861\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 19s 839ms/step - loss: 0.0283 - accuracy: 0.9870\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2c1d2cff90>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"평가 결과 : \", model.evaluate(x_test, y_test)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG1ctXgELPUq",
        "outputId": "b534248b-c0e4-4f6b-e06a-007feba01822"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 2s 57ms/step - loss: 0.2110 - accuracy: 0.9371\n",
            "평가 결과 :  0.9371342658996582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BIO 태그의 경우 실제 의미 있는 태그보다 의미 없는 O 태그가 대부분을 차지하고 있어 실제 우리가 원하는 성능과 무관하게 높은 점수로 계산한다. 따라서 개체명 인식에 사용되는 성능 평가는 F1 스코어를 계산하는 방법을 사용해야 한다."
      ],
      "metadata": {
        "id": "Ufx_hOgTVPMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스를 NER 태그로 변환\n",
        "def sequences_to_tag(sequences):\n",
        "  result = []\n",
        "  for sequence in sequences:\n",
        "    temp = []\n",
        "    for pred in sequence: \n",
        "      pred_index = np.argmax(pred)\n",
        "      temp.append(index_to_ner[pred_index].replace(\"PAD\", \"0\"))\n",
        "    result.append(temp)\n",
        "  return result"
      ],
      "metadata": {
        "id": "IHgL4zstLUc2"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터셋의 NER 예측\n",
        "y_predicted = model.predict(x_test) # (711, 40) => model => (711, 40 , 8)\n",
        "pred_tags = sequences_to_tag(y_predicted) # 예측된 NER\n",
        "test_tags = sequences_to_tag(y_test) # 실제 NER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2GN2Ao4La_B",
        "outputId": "794af187-b47f-461d-86b2-d98a4e9d7f81"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 1s 57ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7D7kc1BSIq2",
        "outputId": "392b4fc3-50f8-45e8-eb8e-ddf9cf615bc3"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=7421edaf731b4920d30d7f6acbc66d7a979ef13e66d843d787c3c86a4e4019f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 스코어를 계산하기 위해서는 정밀도와 재현율을 사용해야 하낟.\n",
        "\n",
        "- 정확도 (Accuracy) : 실제 정답과 얼마나 유사한지 나타낸다.\n",
        "- 정밀도 (Precision) : 정밀도가 높다고 해서 정확하다는 의미는 아니다. 정밀도가 높으면 결과값이 일정하게 분포되어 있는 것이다.\n",
        "- 재현율 (Recall) : 실제 정답인 것들 중 예측 모델이 정답이라 예측한 것의 비율\n",
        "\n",
        "F1 스코어란 정밀도와 재현율의 조화 평균을 의미한다.\n",
        "\n",
        "위에서 predict() 함수를 통해 테스트용 데이터셋의 결과를 예측하고, 해당 함수의 입력으로 시퀀스 번호로 인코딩된 테스트용 단어 시퀀스(넘파이 배열)를 사용한다. 해당 함수의 결과로는 예측된 NER 태그 정보가 담긴 넘파이 배열이 반환된다.\n",
        "\n",
        "seqeval.metrics 모듈의 classification_report() 함수를 통해 NER 태그별로 계싼된 정밀도와 재현율 그리고 F1 스코어를 출력한다. f1_score() 함수를 통해 F1 스코어만 불러올 수도 있다. "
      ],
      "metadata": {
        "id": "o8MJcZ49VcaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 스코어 계산을 위해 사용\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "print(classification_report(test_tags, pred_tags))\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu0VmgQhMQv2",
        "outputId": "b2797286-a2d0-4da9-b3e7-51d61b46f412"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_DT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_PS seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_OG seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_TI seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_LC seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           _       0.60      0.53      0.56       644\n",
            "         _DT       0.87      0.87      0.87       335\n",
            "         _LC       0.76      0.51      0.61       312\n",
            "         _OG       0.71      0.56      0.62       481\n",
            "         _PS       0.81      0.41      0.55       374\n",
            "         _TI       0.93      0.64      0.76        66\n",
            "\n",
            "   micro avg       0.73      0.57      0.64      2212\n",
            "   macro avg       0.78      0.59      0.66      2212\n",
            "weighted avg       0.73      0.57      0.63      2212\n",
            "\n",
            "F1-score: 63.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 유형의 문장 NER 예측\n",
        "word_to_index = sent_tokenizer.word_index\n",
        "#new_sentence = '삼성전자 출시 스마트폰 오늘 애플 도전장 내밀다.' .split()\n",
        "new_sentence = '쟈니스 소속 가수인 아라시는 오늘 앨범을 발매한다.'.split()\n",
        "new_x = []\n",
        "for w in new_sentence:\n",
        "  try:\n",
        "    new_x.append(word_to_index.get(w,1))\n",
        "  except KeyError:\n",
        "    # 모르는 단어의 경우 OOV\n",
        "    new_x.append(word_to_index['OOV'])"
      ],
      "metadata": {
        "id": "gmvQR79sMiTn"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"새로운 유형의 시퀀스 : \", new_x)\n",
        "new_padded_seqs = preprocessing.sequence.pad_sequences([new_x], padding=\"post\", value=0, maxlen=max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33uP2ADZM_MO",
        "outputId": "414937a4-9c1e-49e8-b61b-b09142a40bbe"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "새로운 유형의 시퀀스 :  [1, 685, 1, 1, 286, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NER 예측\n",
        "p = model.predict(np.array([new_padded_seqs[0]]))\n",
        "p = np.argmax(p, axis=-1) # 예측된 NER 인덱스값 추출"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MhPUiVcNReE",
        "outputId": "4e23f0dc-8f2a-4b28-e2ff-67a176137008"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 39ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{:10} {:5}\".format(\"단어\", \"예측된 NER\"))\n",
        "print(\"-\" * 50)\n",
        "for w, pred in zip(new_sentence, p[0]):\n",
        "  print(\"{:10} {:5}\".format(w, index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL0BB9iRNW85",
        "outputId": "71bf4d10-031d-42fc-8ba4-0f9508315f7d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어         예측된 NER\n",
            "--------------------------------------------------\n",
            "쟈니스        I    \n",
            "소속         O    \n",
            "가수인        O    \n",
            "아라시는       I    \n",
            "오늘         B_DT \n",
            "앨범을        I    \n",
            "발매한다.      I    \n"
          ]
        }
      ]
    }
  ]
}