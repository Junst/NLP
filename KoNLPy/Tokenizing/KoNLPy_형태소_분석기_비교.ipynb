{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# KoNLPy\n",
        "##Kkma\n",
        "Kkma는 서울대학교 Intelligent Data Systems 연구실에서 자연어 처리를 위해 개발한 한국어 형태소 분석기이다. Kkma는 \"꼬꼬마\"로 발음되며, GPL v2 라이선스를 따른다. KoNLPy의 꼬꼬마 형태소 분석기를 사용해보자"
      ],
      "metadata": {
        "id": "6rD_blf9Le1z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y6mZDWKLdqD",
        "outputId": "66898dec-bd38-481b-f2b7-4134ed266322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy\n",
        "from konlpy.tag import Kkma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# morphs(phrase) : 인자로 입력한 문장을 형태소 단위로 토크나이징한다. 토크나이징된 형태소들은 리스트 형태로 반환한다.\n",
        "# nouns(phrase) : 인자로 입혁한 문장에서 명사인 토큰만 추출한다.\n",
        "# pos(phrase) : POS tagger라 부르며, 인자로 입력한 문장에서 형태소를 추출한 뒤 품사 태깅을 한다. 추출된 형태소와 그 형태소의 품사가 튜플 형태로 묶여서 리스트로 반환된다.\n",
        "# sentences(phrase) : 인자로 입력한 여러 문장을 분리해주는 역할을 한다. 분리된 문장은 리스트 형태로 반환된다."
      ],
      "metadata": {
        "id": "wauFqoFLL6og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 꼬꼬마 형태소 분석기 객체 생성\n",
        "kkma = Kkma()\n",
        "\n",
        "text = \"온 몸으로 바람을 모두 모아서 힘을 합치자! 아라시! 아라시! 포드림!\"\n",
        "\n",
        "#형태소 추출\n",
        "morphs = kkma.morphs(text)\n",
        "print(morphs)\n",
        "\n",
        "#형태소와 품사 태그 추출\n",
        "pos = kkma.pos(text)\n",
        "print(pos)\n",
        "\n",
        "# 명사만 추출\n",
        "nouns = kkma.nouns(text)\n",
        "print(nouns)\n",
        "\n",
        "# 문장 분리\n",
        "\n",
        "sentences = \"안녕하세요? 저희는 아라시입니다.\"\n",
        "s = kkma.sentences(sentences)\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb5ghv_EMmdg",
        "outputId": "efe9fb9c-1fe5-4c39-e632-7282f30af667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['오', 'ㄴ', '몸', '으로', '바람', '을', '모두', '모으', '아서', '힘', '을', '합치', '자', '!', '아', '라', '시', '!', '아', '라', '시', '!', '포', '드림', '!']\n",
            "[('오', 'VV'), ('ㄴ', 'ETD'), ('몸', 'NNG'), ('으로', 'JKM'), ('바람', 'NNG'), ('을', 'JKO'), ('모두', 'MAG'), ('모으', 'VV'), ('아서', 'ECD'), ('힘', 'NNG'), ('을', 'JKO'), ('합치', 'VV'), ('자', 'ECE'), ('!', 'SF'), ('아', 'VV'), ('라', 'ECD'), ('시', 'NNG'), ('!', 'SF'), ('아', 'VV'), ('라', 'ECD'), ('시', 'NNG'), ('!', 'SF'), ('포', 'NNG'), ('드림', 'NNG'), ('!', 'SF')]\n",
            "['몸', '바람', '힘', '시', '포', '포드림', '드림']\n",
            "['안녕하세요?', '저희는 아라 시입니다.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Komoran\n",
        "Komoran(Korean Morphological ANalyzer)은 Shinewate에서 자바로 개발한 한국어 형태소 분석기이다. '코모란'으로 발음하여, Apache 라이선스 2.0을 따르는 오픈소스 소프트웨어이다. 정량화 버전도 존재하며, 다른 형태소 분석기와 다르게 공백이 포함된 형태소 단위로도 분석이 가능해 많이 사용한다."
      ],
      "metadata": {
        "id": "4fPC6AoPNgn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Komoran"
      ],
      "metadata": {
        "id": "YgHCxEEvM5xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# morphs(phrase) : 인자로 입력한 문장을 형태소 단위로 토크나이징합니다. 토크나이징된 형태소들은 리스트 형태로 반환한다.\n",
        "# nouns(phrase) : 인자로 입력한 문장에서 품사가 명사인 토큰들만 추출한다.\n",
        "# pos(phrase, flatten=True) : POS tagger라 부르며, 인자로 입력한 문장에서 형태소를 추출한 뒤 품사 태깅을 합니다. 추출된 형태소와 그 형태소의 품사가 튜플 형태로 묶여서 리스트로 반환된다."
      ],
      "metadata": {
        "id": "sncr6hy7N1ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코모란 형태소 분석기 객체 생성\n",
        "komoran = Komoran()\n",
        "\n",
        "text = \"온 몸으로 바람을 모두 모아서 힘을 합치자! 아라시! 아라시! 포드림!\"\n",
        "\n",
        "# 형태소 추출\n",
        "morphs = komoran.morphs(text)\n",
        "print(morphs)\n",
        "\n",
        "# 형태소와 품사 태그 추출\n",
        "pos = komoran.pos(text)\n",
        "print(pos)\n",
        "\n",
        "# 명사만 추출\n",
        "nouns = komoran.nouns(text)\n",
        "print(nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T2dNvUSOID2",
        "outputId": "7bf658aa-7df4-47b7-e20e-7246eb9e216d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['오', 'ㄴ', '몸', '으로', '바람', '을', '모두', '모으', '아서', '힘', '을', '합치', '자', '!', '아라시', '!', '아라시', '!', '포드', '림', '!']\n",
            "[('오', 'VV'), ('ㄴ', 'ETM'), ('몸', 'NNG'), ('으로', 'JKB'), ('바람', 'NNG'), ('을', 'JKO'), ('모두', 'MAG'), ('모으', 'VV'), ('아서', 'EC'), ('힘', 'NNG'), ('을', 'JKO'), ('합치', 'VV'), ('자', 'EF'), ('!', 'SF'), ('아라시', 'NNP'), ('!', 'SF'), ('아라시', 'NNP'), ('!', 'SF'), ('포드', 'NNP'), ('림', 'NNP'), ('!', 'SF')]\n",
            "['몸', '바람', '힘', '아라시', '아라시', '포드', '림']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Okt\n",
        "Okt(Open-source Korean Text Processor)는 트위터에서 개발한 Twitter 한국어 처리기에서 파생된 오픈소스(아파치 2.0 라이선스) 한국어 처리기이다.\n",
        "\n",
        "공식 홈페이지에 따르면 Okt는 빅데이터에서 간단한 한국어 처리를 통해 색인어를 추출하는 목표를 갖고 있기 때문에 완전한 수준의 형태소 분석을 지향하지 않는다. Okt는 띄어쓰기가 어느정도 되어 있는 문장ㅇ을 빠르게 분석할 때 많이 사용한다."
      ],
      "metadata": {
        "id": "mw-4kvpVOlFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "Xj41qLXcPKMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# morphs(phrase) : 인자로 입력한 문장을 형태소 단위로 토크나이징합니다. 토크나이징된 형태소들은 리스트 형태로 반환된다.\n",
        "# nouns(phrase) : 인자로 입력한 문장에서 품사가 명사인 토큰들만 추출합니다.\n",
        "# pos(phrase, stem=False, joun=False) : POS tagger라부르며, 인자로 입력한 문장에서 형태소를 추출한 뒤 품사 태깅을 합니다. 추출된 형태소와 그 형태소의 품사가 튜플 형태로 묶여서 리스트로 반환된다.\n",
        "# normalize(phrase) : 입력한 문장을 정규화한다. ex) 정규화 이전 : 아라싴ㅋㅋㅋ개웃곀ㅋㅋㅋ // 정규화 이후 : 아라시 ㅋㅋㅋㅋ 개웃겨 ㅋㅋㅋㅋ\n",
        "# phrases(phrase) : 입력한 문장에서 어구를 추출한다. ex) 입력 : \"오늘 아라시가 보고싶네요.\" 출력 : ['오늘', '오늘 아라시', '아라시']"
      ],
      "metadata": {
        "id": "pm27DAuFPKEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okt=Okt()\n",
        "\n",
        "text = \"온 몸으로 바람을 모두 모아서 힘을 합치자! 아라시! 아라시! 포드림!\"\n",
        "\n",
        "# 형태소 추출\n",
        "morphs = okt.morphs(text)\n",
        "print(morphs)\n",
        "\n",
        "# 형태소와 품사 태그 추출\n",
        "pos = okt.pos(text)\n",
        "print(pos)\n",
        "\n",
        "# 명사만 추출\n",
        "nouns = okt.nouns(text)\n",
        "print(nouns)\n",
        "\n",
        "# 정규화, 어구 추출\n",
        "text = \" 아라싴ㅋㅋㅋ 개웃곀ㅋㅋㅋ\"\n",
        "print(okt.normalize(text))\n",
        "print(okt.phrases(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0jAZ4p3Pq-a",
        "outputId": "0416e6b2-8c9f-4083-85c8-70b698a57ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['온', '몸', '으로', '바람', '을', '모두', '모아서', '힘', '을', '합치', '자', '!', '아라시', '!', '아라시', '!', '포', '드림', '!']\n",
            "[('온', 'Noun'), ('몸', 'Noun'), ('으로', 'Josa'), ('바람', 'Noun'), ('을', 'Josa'), ('모두', 'Noun'), ('모아서', 'Verb'), ('힘', 'Noun'), ('을', 'Josa'), ('합치', 'Noun'), ('자', 'Suffix'), ('!', 'Punctuation'), ('아라시', 'Noun'), ('!', 'Punctuation'), ('아라시', 'Noun'), ('!', 'Punctuation'), ('포', 'Noun'), ('드림', 'Noun'), ('!', 'Punctuation')]\n",
            "['온', '몸', '바람', '모두', '힘', '합치', '아라시', '아라시', '포', '드림']\n",
            " 아라시ㅋㅋㅋ 개웃겨ㅋㅋㅋ\n",
            "['아라싴', '개웃곀']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okt는 트위터 빅데이터 기반이라 그런지 아라시가 인식이 잘 된다!! 포랑 드림도 잘 구분하는 것으로 보인다."
      ],
      "metadata": {
        "id": "gHREY9HVQKMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Komoran 미등록 단어 형태소 분석"
      ],
      "metadata": {
        "id": "ifZf-obzQq_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Komoran\n",
        "\n",
        "komoran = Komoran()\n",
        "text = \"우리 아라시에 관련된 엔엘피 챗봇 만들까?\"\n",
        "pos = komoran.pos(text)\n",
        "print(pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHsnDCPzQt7T",
        "outputId": "a16b0a23-0800-4376-fc4a-dbd0d9841e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('우리', 'NP'), ('아라시', 'NNP'), ('에', 'JKB'), ('관련', 'NNG'), ('되', 'XSV'), ('ㄴ', 'ETM'), ('엔', 'NNB'), ('엘', 'NNP'), ('피', 'NNG'), ('챗봇', 'NA'), ('만들', 'VV'), ('ㄹ까', 'EF'), ('?', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [단어] Tab [품사]\n",
        "엔엘피  NNG\n",
        "여름의 사랑은 무지개 색으로 빛난다  NNG\n",
        "\n",
        "위의 형식대로 TSV 파일로 저장 후, 불러온다.\n",
        "tsv 저장 방법 : Excel에서 저장 후, 복사해서 Notepad++에 붙여넣고 tsv 파일로 저장한다.\n"
      ],
      "metadata": {
        "id": "T1tkXN4WSLsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "komoran = Komoran(userdic='komoranregister.tsv')\n",
        "text = \"우리 아라시에 관련된 엔엘피 챗봇 만들까?\"\n",
        "pos = komoran.pos(text)\n",
        "print(pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijNO3LvxRBb3",
        "outputId": "aa9870a3-1409-4e01-aa59-2f46bd5b1a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('우리', 'NP'), ('아라시', 'NNP'), ('에', 'JKB'), ('관련', 'NNG'), ('되', 'XSV'), ('ㄴ', 'ETM'), ('엔엘피', 'NNG'), ('챗봇', 'NA'), ('만들', 'VV'), ('ㄹ까', 'EF'), ('?', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"여름의 사랑은 무지개 색으로 빛난다\"\n",
        "pos = komoran.pos(text)\n",
        "print(pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEyXTof-S8ld",
        "outputId": "f4823dde-36f3-4ae0-d1f0-59842fec624a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('여름의 사랑은 무지개 색으로 빛난다', 'NNG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kkma \n",
        "###장점\n",
        "분석 품질이 좋다.\n",
        "지원하는 품사 태그가 가장 많다. \n",
        "\n",
        "###단점\n",
        "분석 속도가 느리다. \n",
        "사용자 시전으로 추가한 복합 명사에 대해 불완전하게 동작한다.\n",
        "\n",
        "# Komoran\n",
        "###장점\n",
        "자소가 분리된 문장이나 오탈자에 강하다.\n",
        "사용자의 사전 관리가 용이하다.\n",
        "\n",
        "###단점\n",
        "적당한 분석 품질과 분석 속도를 가진다.\n",
        "\n",
        "# Okt\n",
        "###장점\n",
        "매우 빠른 분석 속도를 가진다.\n",
        "정규화 기능을 지원한다.\n",
        "\n",
        "###단점\n",
        "사용자 사전 관리가 어렵다.\n",
        "용언 분석에 일관성이 부족하다."
      ],
      "metadata": {
        "id": "rMFdGKt6UwG6"
      }
    }
  ]
}